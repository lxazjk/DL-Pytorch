{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846085ca",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "## 图像识别的特性\n",
    "\n",
    "平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "\n",
    "局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。\n",
    "\n",
    "## 从全连接层到卷积神经网络\n",
    "\n",
    "一般的来说 设计全连接层 我们需要思维的张量(从(k, l) -> (i, j))的一一映射\n",
    "\n",
    "形式的\n",
    "\n",
    "$$H_{i, j} = b_{i, j} + \\sum_{k} \\sum_{l} w_{i, j, k, l} a_{k, l}$$\n",
    "$$H_{i, j} = b_{i, j} + \\sum_{a} \\sum_{b} v_{i, j, a, b} a_{a+i, b+j}$$\n",
    "从数学的角度利用`平移不变性`和`局部性` 两个特点\n",
    "\n",
    "### 平移不变性\n",
    "\n",
    "由平移不变性 我们可以知道 $v_{i, j, a, b} = v_{a, b}$ 及 平移的过程中, 卷积的`kernel`核函数 是不会变的\n",
    "\n",
    "### 局部性\n",
    "\n",
    "局部性告诉我们 并不是需要枚举所有的范围,我们只需要枚举一个局部,及$a, b \\in [-\\Delta, \\Delta]$\n",
    "\n",
    "## 形式化的\n",
    "我们得到\n",
    "$$H_{i, j} = b_{i, j} + \\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta} v_{a, b} a_{a+i, b+j}$$\n",
    "\n",
    "所以 我们只需要训练获得$V_{a, b}, a, b \\in [-\\Delta, \\Delta]$\n",
    "\n",
    "## 更进一步的\n",
    "图像还有一个`C`作为参数,及通道数 (如图像一般由`R,G,B`三个通道组成)所以我们需要转变形式,为了实现多输入多输出我们得到\n",
    "\n",
    "$$H_{i, j, d} = b_{i, j} + \\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta} \\sum_{c} v_{a, b, c, d} a_{a+i, b+j, c}$$\n",
    "\n",
    "## 通过训练得到核函数\n",
    "\n",
    "`e.g.` 检测垂直`0, 1`边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0daf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be15c2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "46915798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]]) \n",
      " tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]) \n",
      " torch.Size([6, 7])\n"
     ]
    }
   ],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super.__init__()\n",
    "        self.weight = nn.Parameter(kernel_size)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias\n",
    "\n",
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "Kernel = torch.tensor([[1, -1]])\n",
    "Y = corr2d(X, Kernel)\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
    "print(X, '\\n', Y, '\\n', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "65007341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.000\n",
      "epoch 4, loss 0.000\n",
      "epoch 6, loss 0.000\n",
      "epoch 8, loss 0.000\n",
      "epoch 10, loss 0.000\n",
      "tensor([[ 1.0000, -1.0000]])\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epoch = 10\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "for i in range(num_epoch):\n",
    "    y_hat = conv2d(X)\n",
    "    loss = (Y - y_hat) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    loss.sum().backward()\n",
    "    with torch.no_grad():\n",
    "        conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i+1}, loss {loss.sum():.3f}')\n",
    "print(conv2d.weight.data.reshape(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b73a76",
   "metadata": {},
   "source": [
    "## 步长 stride 填充 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "549d2fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(8, 8))\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) # api = padding 上下左右填充1\n",
    "X = torch.rand(size=(8, 8))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "print(comp_conv2d(conv2d, X).shape)\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "print(comp_conv2d(conv2d, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c1769",
   "metadata": {},
   "source": [
    "## 多输入多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "78a2c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]]) \n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [3., 4.]]])\n",
      "torch.Size([3, 2, 2, 2])\n",
      "tensor([[[ 56.,  72.],\n",
      "         [104., 120.]],\n",
      "\n",
      "        [[ 76., 100.],\n",
      "         [148., 172.]],\n",
      "\n",
      "        [[ 96., 128.],\n",
      "         [192., 224.]]])\n"
     ]
    }
   ],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))\n",
    "\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)\n",
    "print(X, '\\n', K)\n",
    "\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "print(K.shape)\n",
    "print(corr2d_multi_in_out(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27140630",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "\n",
    "https://blog.csdn.net/qq_40507857/article/details/119854085\n",
    "\n",
    "\n",
    "一句话概括`cat`和`stack`的区别的话就是:`cat`之后维度是不变的,`stack`之后维度会增加1\n",
    "\n",
    "[2, 3]按照dim=0 `cat`得到的是[4, 3], `stack`得到的是`[2, 2, 3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8a36d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [7., 8.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "print(pool2d(X, (2, 2)))\n",
    "\n",
    "print(pool2d(X, (2, 2), 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ba2fffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.,  7.],\n",
      "          [13., 15.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "print(pool2d(X))\n",
    "X = torch.cat((X, X + 1), 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd74a0",
   "metadata": {},
   "source": [
    "在 PyTorch 中，张量的形状由 torch.Size([...]) 表示，每个维度具有特定的意义，特别是在处理卷积神经网络（CNN）时。对于给定的张量形状 torch.Size([1, 2, 4, 4])，其含义如下：\n",
    "\n",
    "`第一维度 (1)`: 这通常表示批大小`(batch size)`，即一次处理的样本数量。在这个例子中，批大小为1，表示一次只处理一个样本。\n",
    "\n",
    "`第二维度 (2)`: 在大多数CNN应用中，第二维度代表通道数`(channels)`。这可以是输入通道的数量，如果这是输入数据的张量的话。在这个例子中，它表示有2个输入通道。\n",
    "\n",
    "`第三和第四维度 (4, 4)`: 这两个维度通常表示每个通道的空间维度，即图像的高度和宽度。在这里，每个通道的图像大小是4x4像素。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
